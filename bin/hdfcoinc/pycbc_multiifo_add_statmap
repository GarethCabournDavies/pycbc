#!/bin/env python
""" Reduce IFAR for coincidences in times with more than one ifo combination
available. Cluster for best IFAR. This clusters to find the most
significant foreground, but leaves the background triggers alone.
"""

import h5py, numpy as np, argparse, logging, pycbc, pycbc.events, pycbc.io, lal
import pycbc.version
import pycbc.conversions as conv
from pycbc.events import coinc
from ligo import segments
import itertools

parser = argparse.ArgumentParser()
parser.add_argument("--version", action="version", version=pycbc.version.git_verbose_msg)
parser.add_argument('--verbose', action='store_true')
parser.add_argument('--statmap-files', nargs='+',
                    help="List of coinc files to be redistributed")
parser.add_argument('--cluster-window', type=float)
parser.add_argument('--output-file', help="name of output file")
args = parser.parse_args()

pycbc.init_logging(args.verbose)

files = [h5py.File(n, 'r') for n in args.statmap_files]

f = h5py.File(args.output_file, "w")

logging.info('Copying segments and attributes to %s' % args.output_file)
# Move segments information into the final file - remove some duplication
# in earlier files
for fi in files:
    for key in fi['segments']:
        if key.startswith('foreground') or key.startswith('background'):
            continue
        f['segments/%s/end' % key] = fi['segments/%s/end' % key][:]
        f['segments/%s/start' % key] = fi['segments/%s/start' % key][:]
        if 'segments/foreground_veto' in fi:
            f['segments/%s/foreground_veto/end' % key] = \
                                         fi['segments/foreground_veto/end'][:]
            f['segments/%s/foreground_veto/start' % key] = \
                                       fi['segments/foreground_veto/start'][:]
        for attr_name in fi.attrs:
            if key not in f:
                 f.create_group(key)
            f[key].attrs[attr_name] = fi.attrs[attr_name]

logging.info('Combining foreground and foreground excluded segments')
# Set up dictionaries to contain segments from the individual statmap files
indiv_segs = segments.segmentlistdict({})

# loop through statmap files and put segments into segmentlistdicts
for fi in files:
    key = fi.attrs['ifos'].replace(' ','')
    # get analysed segments from individual statmap files
    starts = fi['segments/{}/start'.format(key)][:]
    ends = fi['segments/{}/end'.format(key)][:]
    indiv_segs[key] = pycbc.events.veto.start_end_to_segments(starts, ends)

# Convert segmentlistdict to a list ('seglists') of segmentlists
# then np.sum(seglists, axis=0) does seglists[0] + seglists[1] + ...
foreground_segs = np.sum(list(indiv_segs.values()), axis=0)
# obtain list of all ifos involved in the coinc_statmap files
all_ifos = np.unique([ifo for fi in files
                      for ifo in fi.attrs['ifos'].split(' ')])

# output to file
f.attrs['foreground_time'] = abs(foreground_segs)

logging.info('Copying foreground & background common datasets')
keys_to_copy = ['decimation_factor', 'stat']
fg_bg = ['foreground','background', 'background_exc']
for fg_type in fg_bg:
    for k in keys_to_copy:
        pycbc.io.combine_and_copy(f, files, fg_type + '/' + k)

fg_only_keys_to_copy = ['template_id','timeslide_id', 'ifar', 'ifar_exc']
logging.info('Copying foreground-only datasets')
for k in fg_only_keys_to_copy:
    pycbc.io.combine_and_copy(f, files, 'foreground/' + k)

logging.info('Collating triggers into single structure')

all_trig_times = {}
all_trig_ids = {}
for ifo in all_ifos:
    all_trig_times[ifo] = np.array([], dtype=np.uint32)
    all_trig_ids[ifo] = np.array([], dtype=np.uint32)

# For each file, append the trigger time and id data for each ifo
# If an ifo does not participate in any given coinc then fill with -1 values
for f_in in files:
    for ifo in all_ifos:
        if ifo in f_in['foreground']:
            all_trig_times[ifo] = np.concatenate([all_trig_times[ifo], \
                                    f_in['foreground/{}/time'.format(ifo)][:]])
            all_trig_ids[ifo] = np.concatenate([all_trig_ids[ifo],
                              f_in['foreground/{}/trigger_id'.format(ifo)][:]])
        else:
            all_trig_times[ifo] = np.concatenate([all_trig_times[ifo],
                                 -1*np.ones_like(f_in['foreground/fap'][:],
                                                    dtype=np.uint32)])
            all_trig_ids[ifo] = np.concatenate([all_trig_ids[ifo],
                                 -1*np.ones_like(f_in['foreground/fap'][:],
                                                    dtype=np.uint32)])

for ifo in all_ifos:
    f['foreground/{}/time'.format(ifo)] = all_trig_times[ifo]
    f['foreground/{}/trigger_id'.format(ifo)] = all_trig_ids[ifo]

logging.info('Getting ifo combination information for each coincidence')
for f_in in files:
    key = f_in.attrs['ifos'].replace(' ','')

    for fg_type in fg_bg:
        ifo_combo_key = fg_type + '/ifo_combination'
        fg_comb_repeat = np.array(np.repeat(key.encode('utf8'),
                                            f_in[fg_type + '/stat'].size))
        if ifo_combo_key in f:
            ifo_comb_fg = f[ifo_combo_key][:]
            del f[ifo_combo_key]
            ifo_comb_fg = np.concatenate([ifo_comb_fg, fg_comb_repeat])
        else:
            ifo_comb_fg = fg_comb_repeat

        f[ifo_combo_key]=ifo_comb_fg

del fg_comb_repeat, ifo_comb_fg

logging.info('Working available ifo combinations are available for each '
             'coincidence')

logging.info('Finding indices of which background events are from which detector combination')

where_combo = {ifo_c:np.where(f['background/ifo_combination'][:]==ifo_c)[0]
               for ifo_c in f['segments'] if ifo_c is not 'foreground_veto'}
where_combo_exc = {ifo_c:np.where(f['background_exc/ifo_combination'][:]==ifo_c)[0]
               for ifo_c in f['segments'] if ifo_c is not 'foreground_veto'}

logging.info('{} triggers'.format(f['foreground/ifar'].size))
ifar_stat = np.core.records.fromarrays([f['foreground/ifar'][:],
                                        f['foreground/stat'][:]],
                                        names='ifar,stat')

# all_times is a tuple of trigger time arrays
all_times = (f['foreground/%s/time' % ifo][:] for ifo in all_ifos)

def argmax(v):
    return np.argsort(v)[-1]

# Currently only clustering zerolag, i.e. foreground, so set all timeslide_ids
# to zero
cidx = pycbc.events.cluster_coincs_multiifo(ifar_stat, all_times,
                                            np.zeros(len(ifar_stat)), 0,
                                            args.cluster_window, argmax)

def filter_dataset(h5file, name, idx):
    # Dataset needs to be deleted and remade as it is a different size
    filtered_dset = h5file[name][:][idx]
    del h5file[name]
    h5file[name] = filtered_dset

# Downsample the foreground columns to only the loudest ifar between the
# multiple files
for key in f['foreground'].keys():
    if key not in all_ifos:
        filter_dataset(f, 'foreground/%s' % key, cidx)
    else:  # key is an ifo
        for k in f['foreground/%s' % key].keys():
            filter_dataset(f, 'foreground/{}/{}'.format(key, k), cidx)

times_tuple = (f['foreground/{}/time'.format(ifo)] for ifo in all_ifos)
test_times = np.array([pycbc.events.mean_if_greater_than_zero(tc)[0]
                          for tc in zip(*times_tuple)])

is_in_combo_time = {}
for key in f['segments']:
    is_in_combo_time[key] = np.zeros_like(f['foreground/decimation_factor'][:])
    if key.startswith('foreground') or key.startswith('background'):
        continue
    end_times = np.array(f['segments/%s/end' % key][:])
    start_times = np.array(f['segments/%s/start' % key][:])
    idx_within_segment = pycbc.events.indices_within_times(test_times,
                                                           start_times,
                                                           end_times)
    is_in_combo_time[key][idx_within_segment] += np.ones_like(idx_within_segment)
del idx_within_segment


all_indices = np.arange(f['foreground/decimation_factor'].size)
available_combos =[' '.join(sorted([key for key in is_in_combo_time if is_in_combo_time[key][i]])).encode('utf8') for i in all_indices]
del all_indices
f['foreground/available_combinations'] = available_combos

all_combo_types = np.unique(available_combos)
idx = {ct:np.where(np.array(available_combos)==ct)[0]
       for ct in all_combo_types}

del available_combos

logging.info('Recalculating ifar according to summed trigger distributions')

fg_ifar = np.zeros_like(f['foreground/decimation_factor'][:])
fg_ifar_exc = np.zeros_like(f['foreground/decimation_factor'][:])

for ct in all_combo_types:
    cts = ct.split(' ')
    if len(cts) == 1:
        logging.info('Copying over triggers which are only in {} time'.format(ct))
        # If only one combination is available, then the stat is the same
        # as previously calulated
        fg_ifar[idx[ct]] = f['foreground/ifar'][:][idx[ct]]
        fg_ifar_exc[idx[ct]] = f['foreground/ifar_exc'][:][idx[ct]]
        continue
    logging.info('Recalculating ifar for coincidences which are in {} time'.format(ct))
    largest_combination = cts[np.argmax([len(ifo_c) for ifo_c in cts])]
    bg_time = f[largest_combination].attrs['background_time']
    bg_time_exc = f[largest_combination].attrs['background_time_exc']
    inc_bg_list = [where_combo[ifo_c] for ifo_c in cts]
    inc_bg = list(itertools.chain(*inc_bg_list))
    inc_bg_exc_list = [where_combo_exc[ifo_c] for ifo_c in cts]
    inc_bg_exc = list(itertools.chain(*inc_bg_exc_list))
    _, fnlouder = coinc.calculate_n_louder(f['background/stat'][:][inc_bg],
                                           f['foreground/stat'][:][idx[ct]],
                                           f['background/decimation_factor'][:][inc_bg])
    _, fnlouder_exc = coinc.calculate_n_louder(
                          f['background_exc/stat'][:][inc_bg_exc],
                          f['foreground/stat'][:][idx[ct]],
                          f['background_exc/decimation_factor'][:][inc_bg_exc]
                                              )
    ifar = bg_time / (fnlouder + 1)
    ifar_exc = bg_time_exc / (fnlouder_exc + 1)
    fg_ifar[idx[ct]] = conv.sec_to_year(ifar)
    fg_ifar_exc[idx[ct]] = conv.sec_to_year(ifar_exc)

for bg_type in ['background', 'background_exc']:
    for k in ['stat','decimation_factor', 'ifo_combination']:
        print(bg_type + '/' + k)
        if bg_type + '/' + k in f:
            print('deleting')
            del f[bg_type + '/' + k]
        else: print('not deleting')

f['foreground/ifar'][:] = fg_ifar
f['foreground/fap'] = 1 - np.exp(-f.attrs['foreground_time'] / fg_ifar)
f['foreground/ifar_exc'][:] = fg_ifar_exc
f['foreground/fap_exc'] = 1 - np.exp(-f.attrs['foreground_time_exc'] / fg_ifar_exc)

f.close()
logging.info('Done!')
